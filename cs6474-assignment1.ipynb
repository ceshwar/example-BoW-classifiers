{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####http://stackoverflow.com/questions/8376691/how-to-remove-hashtag-user-link-of-a-tweet-using-regular-expression\n",
    "import re,string\n",
    "\n",
    "def strip_links(text):\n",
    "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "    links         = re.findall(link_regex, text)\n",
    "    for link in links:\n",
    "        text = text.replace(link[0], ', ')    \n",
    "    return text\n",
    "\n",
    "def strip_all_entities(text):\n",
    "    ###strip only @mentions and not #hashtags!\n",
    "    entity_prefixes = ['@']\n",
    "#     entity_prefixes = ['@','#']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in entity_prefixes :\n",
    "            text = text.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "# tests = [\n",
    "#     \"@peter I really love that shirt at #Macy. http://bet.ly//WjdiW4\",\n",
    "#     \"@shawn Titanic tragedy could have been prevented Economic Times: Telegraph.co.ukTitanic tragedy could have been preve... http://bet.ly/tuN2wx\",\n",
    "#     \"I am at Starbucks http://4sh.com/samqUI (7419 3rd ave, at 75th, Brooklyn)\",\n",
    "# ]\n",
    "# for t in tests:\n",
    "#     print strip_all_entities(strip_links(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! with pre-processing\n"
     ]
    }
   ],
   "source": [
    "#remove @mentions and URLs in tweets - preprocessing\n",
    "filename = ['pos_examples_happy.txt', 'neg_examples_sad.txt','pos_examples_PosSentiment.txt', 'neg_examples_NegSentiment.txt']\n",
    "for file_ in filename:\n",
    "    print file_\n",
    "    target = open('data/nohashtags'+file_, 'w')\n",
    "    count = 0\n",
    "\n",
    "    with open('data/'+file_, 'r') as f:\n",
    "        pos_tweets = f.readlines()\n",
    "        for tweet in pos_tweets:\n",
    "            count += 1\n",
    "            target.write(strip_all_entities(strip_links(tweet)))\n",
    "            target.write('\\n')\n",
    "\n",
    "print \"Done! with pre-processing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data = COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "###test on preprocessed data\n",
    "\n",
    "##### load training data\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# suffix = \"\"\n",
    "suffix = \"preprocessed_\"\n",
    "###read tagged sentiment Tweets\n",
    "with open('data/'+suffix+'pos_examples_PosSentiment.txt', 'r') as f:\n",
    "    pos_tweets = f.readlines()\n",
    "\n",
    "with open('data/'+suffix+'neg_examples_NegSentiment.txt', 'r') as f:\n",
    "    neg_tweets = f.readlines()\n",
    "    \n",
    "class_label = 0\n",
    "train_pos = pd.DataFrame(pos_tweets, columns = ['text'])\n",
    "X0 = train_pos.text\n",
    "y0 = np.full(shape=len(X0), fill_value=class_label)\n",
    "\n",
    "###create random 80-20 split\n",
    "rows = random.sample(X0.index, int(0.8*len(X0)))\n",
    "X0_80 = X0.ix[rows]\n",
    "X0_20 = X0.drop(rows)\n",
    "y0_80 = y0[:int(0.8*len(X0))]\n",
    "y0_20 = y0[int(0.8*len(X0)):]\n",
    "###\n",
    "\n",
    "class_label = 1\n",
    "train_neg = pd.DataFrame(neg_tweets, columns = ['text'])\n",
    "X1 = train_neg.text\n",
    "y1 = np.full(shape=len(X1), fill_value=class_label)\n",
    "\n",
    "###create random 80-20 split\n",
    "rows = random.sample(X1.index, int(0.8*len(X1)))\n",
    "X1_80 = X1.ix[rows]\n",
    "X1_20 = X1.drop(rows)\n",
    "y1_80 = y1[:int(0.8*len(X1))]\n",
    "y1_20 = y1[int(0.8*len(X1)):]\n",
    "###\n",
    "\n",
    "X_train = pd.concat((X0_80,X1_80))\n",
    "y_train = np.concatenate((y0_80, y1_80))\n",
    "\n",
    "X_holdout = pd.concat((X0_20,X1_20))\n",
    "y_holdout = np.concatenate((y0_20, y1_20))\n",
    "\n",
    "### load testing data\n",
    "\n",
    "###read tagged sentiment Tweets\n",
    "with open('data/'+suffix+'pos_examples_happy.txt', 'r') as f:\n",
    "    pos_tweets = f.readlines()\n",
    "\n",
    "with open('data/'+suffix+'neg_examples_sad.txt', 'r') as f:\n",
    "    neg_tweets = f.readlines()\n",
    "    \n",
    "import numpy as np\n",
    "class_label = 0\n",
    "train_pos = pd.DataFrame(pos_tweets, columns = ['text'])\n",
    "X0 = train_pos.text\n",
    "y0 = np.full(shape=len(X0), fill_value=class_label)\n",
    "\n",
    "class_label = 1\n",
    "train_neg = pd.DataFrame(neg_tweets, columns = ['text'])\n",
    "X1 = train_neg.text\n",
    "y1 = np.full(shape=len(X1), fill_value=class_label)\n",
    "\n",
    "X_test = pd.concat((X0,X1))\n",
    "y_test = np.concatenate((y0, y1))\n",
    "\n",
    "###\n",
    "print \"Loading data = COMPLETE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done getting top 5000 ngrams!\n"
     ]
    }
   ],
   "source": [
    "##Generate top 5000 ngrams and select random 50\n",
    "###print top 5000 features \n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "##vectorizer arguments blah!\n",
    "\n",
    "tokenizer=None#word_tokenize\n",
    "stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "stop_words.append('rt')\n",
    "ngram_range=(1, 3)\n",
    "lowercase=True\n",
    "max_features=5000\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "\n",
    "###create vectorizer\n",
    "vectorizer = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "                               stop_words=stop_words,\n",
    "                               ngram_range=ngram_range,\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "train_fit = vectorizer.fit_transform(X_train)\n",
    "\n",
    "vocab = vectorizer.vocabulary_\n",
    "arr = (train_fit.toarray().sum(axis=0))\n",
    "\n",
    "with open(\"data/top5000.txt\", \"w\") as f:\n",
    "    for key in vocab:\n",
    "        try:\n",
    "            f.write(str(key) + ',' + str(arr[vocab[key]]) + \"\\n\")\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "print \"Done getting top 5000 ngrams!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 5-fold cross validation \n",
    "###build pipeline; fit on BEST CV MODEL train; predict on test!\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "###5-fold cross validation\n",
    "n_folds = 5\n",
    "kf = KFold(len(X_train), n_folds=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "LinearSVC 0.73578125 0.708153302284 0.795010709336 0.749072562695\n",
      "Fold  2\n",
      "LinearSVC 0.73340625 0.713484091802 0.787794299876 0.748800094226\n",
      "Fold  3\n",
      "LinearSVC 0.73640625 0.711582048957 0.789662327863 0.748591696224\n",
      "Fold  4\n",
      "LinearSVC 0.73459375 0.71769871137 0.780395560791 0.747735170939\n",
      "Fold  5\n",
      "LinearSVC 0.735125 0.711625537695 0.788078224897 0.747903158646\n",
      "predict on holdout data\n",
      "0.738425 0.714594302687 0.79395 0.752184931669\n",
      "predict on test data\n",
      "0.960935738444 0.959020994723 0.963021420519 0.961017044496\n"
     ]
    }
   ],
   "source": [
    "###create pipeline\n",
    "classifier = \"LinearSVC\"\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', vectorizer),\n",
    "#                      ('clf', MultinomialNB(alpha=0.1)),\n",
    "                    ('clf', LinearSVC(C=1.0)),\n",
    "#         (\"clf\", RandomForestClassifier(n_estimators=100, max_features=\"auto\", criterion=\"entropy\", n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "\n",
    "count = 0\n",
    "max_fscore = 0.0\n",
    "best_X_train = X_train\n",
    "best_y_train = y_train\n",
    "best_model = 0\n",
    "\n",
    "for train, test in kf:\n",
    "    count = count + 1\n",
    "    print \"Fold \", count\n",
    "    X_CVtrain, y_CVtrain, X_CVtest, y_CVtest = X_train.values[train], y_train[train], X_train.values[test], y_train[test]\n",
    "    ###fit training data\n",
    "    text_clf = text_clf.fit(X_CVtrain, y_CVtrain)\n",
    "    \n",
    "    ### predict on test data\n",
    "    predicted = text_clf.predict(X_CVtest)\n",
    "\n",
    "    ###get performance metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    accuracy = accuracy_score(y_CVtest,predicted)\n",
    "    precision, recall, fscore, sup = precision_recall_fscore_support(y_CVtest, predicted, average='binary', pos_label=0)\n",
    "    print classifier, accuracy, precision, recall, fscore\n",
    "    \n",
    "    ###update best-model\n",
    "    if max_fscore < fscore: \n",
    "        max_fscore = fscore\n",
    "        best_X_train = X_CVtrain\n",
    "        best_y_train = y_CVtrain\n",
    "        best_model = count - 1\n",
    "        \n",
    "###fit the best SVC model\n",
    "text_clf.fit(best_X_train, best_y_train)\n",
    "\n",
    "print \"predict on holdout data\"\n",
    "predicted = text_clf.predict(X_holdout)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_holdout,predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_holdout, predicted, average='binary', pos_label=0)\n",
    "print accuracy, precision, recall, fscore\n",
    "\n",
    "print \"predict on test data\"\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print accuracy, precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "MNB 0.7289375 0.722249660452 0.736991306539 0.729546021452\n",
      "Fold  2\n",
      "MNB 0.72653125 0.73982473223 0.706133828996 0.722586780789\n",
      "Fold  3\n",
      "MNB 0.73078125 0.724494825037 0.739483116393 0.731912245215\n",
      "Fold  4\n",
      "MNB 0.729 0.744379629023 0.704135408271 0.723698464283\n",
      "Fold  5\n",
      "MNB 0.7294375 0.728057014254 0.729973674314 0.729014084507\n",
      "predict on holdout data\n",
      "0.732225 0.729414670289 0.73835 0.733855137284\n",
      "predict on test data\n",
      "0.955326944758 0.944380260769 0.967643742954 0.95587047916\n"
     ]
    }
   ],
   "source": [
    "###create pipeline\n",
    "classifier = \"MNB\"\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', vectorizer),\n",
    "                     ('clf', MultinomialNB(alpha=0.1)),\n",
    "#                     ('clf', LinearSVC(C=1.0)),\n",
    "#         (\"clf\", RandomForestClassifier(n_estimators=100, max_features=\"auto\", criterion=\"entropy\", n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "\n",
    "count = 0\n",
    "max_fscore = 0.0\n",
    "best_X_train = X_train\n",
    "best_y_train = y_train\n",
    "best_model = 0\n",
    "\n",
    "for train, test in kf:\n",
    "    count = count + 1\n",
    "    print \"Fold \", count\n",
    "    X_CVtrain, y_CVtrain, X_CVtest, y_CVtest = X_train.values[train], y_train[train], X_train.values[test], y_train[test]\n",
    "    ###fit training data\n",
    "    text_clf = text_clf.fit(X_CVtrain, y_CVtrain)\n",
    "    ### predict on test data\n",
    "    predicted = text_clf.predict(X_CVtest)\n",
    "\n",
    "    ###get performance metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    accuracy = accuracy_score(y_CVtest,predicted)\n",
    "    precision, recall, fscore, sup = precision_recall_fscore_support(y_CVtest, predicted, average='binary', pos_label=0)\n",
    "    print classifier, accuracy, precision, recall, fscore\n",
    "    \n",
    "    ###update best-model\n",
    "    if max_fscore < fscore: \n",
    "        max_fscore = fscore\n",
    "        best_X_train = X_CVtrain\n",
    "        best_y_train = y_CVtrain\n",
    "        best_model = count - 1\n",
    "        \n",
    "###fit the best SVC model\n",
    "text_clf.fit(best_X_train, best_y_train)\n",
    "\n",
    "print \"predict on holdout data\"\n",
    "predicted = text_clf.predict(X_holdout)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_holdout,predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_holdout, predicted, average='binary', pos_label=0)\n",
    "print accuracy, precision, recall, fscore\n",
    "\n",
    "print \"predict on test data\"\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print accuracy, precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "RF 0.73115625 0.718309013391 0.753559279325 0.735512036155\n",
      "Fold  2\n",
      "RF 0.73484375 0.726011219368 0.761771995043 0.743461829176\n",
      "Fold  3\n",
      "RF 0.7293125 0.715801394767 0.755140539521 0.734944920441\n",
      "Fold  4\n",
      "RF 0.7309375 0.725349157825 0.750263500527 0.737596001463\n",
      "Fold  5\n",
      "RF 0.72921875 0.720918954962 0.745455685095 0.732982034452\n",
      "predict on holdout data\n",
      "0.731675 0.722989556764 0.75115 0.736800804336\n",
      "predict on test data\n",
      "0.97178692221 0.982753648267 0.960428410372 0.97146278188\n"
     ]
    }
   ],
   "source": [
    "###create pipeline\n",
    "classifier = \"RF\"\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', vectorizer),\n",
    "#                      ('clf', MultinomialNB(alpha=0.1)),\n",
    "#                     ('clf', LinearSVC(C=1.0)),\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=100, max_features=\"auto\", criterion=\"entropy\", n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "\n",
    "count = 0\n",
    "max_fscore = 0.0\n",
    "best_X_train = X_train\n",
    "best_y_train = y_train\n",
    "best_model = 0\n",
    "\n",
    "for train, test in kf:\n",
    "    count = count + 1\n",
    "    print \"Fold \", count\n",
    "    X_CVtrain, y_CVtrain, X_CVtest, y_CVtest = X_train.values[train], y_train[train], X_train.values[test], y_train[test]\n",
    "    ###fit training data\n",
    "    text_clf = text_clf.fit(X_CVtrain, y_CVtrain)\n",
    "    ### predict on test data\n",
    "    predicted = text_clf.predict(X_CVtest)\n",
    "\n",
    "    ###get performance metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    accuracy = accuracy_score(y_CVtest,predicted)\n",
    "    precision, recall, fscore, sup = precision_recall_fscore_support(y_CVtest, predicted, average='binary', pos_label=0)\n",
    "    print classifier, accuracy, precision, recall, fscore\n",
    "    \n",
    "    ###update best-model\n",
    "    if max_fscore < fscore: \n",
    "        max_fscore = fscore\n",
    "        best_X_train = X_CVtrain\n",
    "        best_y_train = y_CVtrain\n",
    "        best_model = count - 1\n",
    "        \n",
    "###fit the best SVC model\n",
    "text_clf.fit(best_X_train, best_y_train)\n",
    "\n",
    "print \"predict on holdout data\"\n",
    "predicted = text_clf.predict(X_holdout)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_holdout,predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_holdout, predicted, average='binary', pos_label=0)\n",
    "print accuracy, precision, recall, fscore\n",
    "\n",
    "print \"predict on test data\"\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print accuracy, precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
