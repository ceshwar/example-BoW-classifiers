{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td> @chief1972 not with my iPhone 1st generation I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td> @mandeev I can't go today.  Give them my love\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td> Ugh\\nHad some awesome unknown Belgian beer ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td> Told Fizul that 2 of my friends are coming. To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td>                          Disturbed by White Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td>                          Working on this fine day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td> needs to see the boy so he can take away all t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td>                                 Sickly  goodnight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td> Good morning driven w/out my ipod.  so sad. Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> heyyy where'd my tweet go?  *shouts to @fusebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>                              Oh no! Bill is dead!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> @ilovemakonnen damnit u just ruined the image ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>                               Working until 230am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>                        has really bad headaches..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> watching Taylor Swift videos from YouTube on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td> @sobeworld the 0 calorie ones are hard 2 find;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td> @itsjudytime ur so lucky!! I love summer!! unl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>          I missed the call from my boo.  Sad face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td> bedtimeee tomorrow prepearing for the last wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>                    I'm going to miss my apartment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td> Weekends almost over  if only the weekdays wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td> everyone please vote for @selenagomez for teen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td> At work... Meeting tonight but I'm kinda out o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>  batting average after today 538 befour today 600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td> Chris Brown is scum ...  justice failed once a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>            @CeCeaKaDiMpLeZ don't sound so excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>           disappointed the didnt win teh glasses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td> @katiehutchison It hasn't been quite that long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td> Lloonngg asss dayy and its no where near over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td> Watching my 13 year ild brother-in-law's baseb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>          sick  just hung out with cousins all day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td> @ceskaholka Wow. four days! I get migraines fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>                              Awww  @ColeTheCondor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td> This train is taking so long. It stops at stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td> Ow my eyes hurt from staring at this screen fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td> @tylercaulfield no fevers\\nNose piercing got h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td> @Meg_Andruschak What?! Still no baby?  I hope ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>                               3.0 broke my iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td> wishing i could go back in time and go to texa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td> Geez....... hockey is over with till October. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>                         may head to bed try sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td> Time for some much needed sleep\\nthe boo says ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td> being sad about losing followers..i be oh so b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td> @Kristofer_Krack Oh man! You can't punish ME f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td> @Shesirawr @evvss pmnya baca aja  http://myloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>               I don't think i like twitter so far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td> 7 games to 0 Mancala ass beating administered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td> Next will be English class for kindy.  I wish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>                      I wanted orange chicken too!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td> @KezzieN you're not the only one.Here my MTV d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td> Boyfriend was all sad and gloomy last night.al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td> I am enjoying my time here but missing my husb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>               I had a really long scary nightmare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td> @PatrickAvis Stretching and rest\\n@disobedient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td> @moregAAn I know... It just makes me sad. Who'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td> @jen_n_em The link sends me to my Fb home page...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td> OMGGGG havent tweeted for so long  id just lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td> @Dragonrider80 sounds painfull poor thing  yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td> just found that last fm is no longer free radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td> @nicholasbraun atleast you get to sleep all da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50080 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   @chief1972 not with my iPhone 1st generation I...\n",
       "1   @mandeev I can't go today.  Give them my love\\...\n",
       "2   Ugh\\nHad some awesome unknown Belgian beer ton...\n",
       "3   Told Fizul that 2 of my friends are coming. To...\n",
       "4                            Disturbed by White Light\n",
       "5                            Working on this fine day\n",
       "6   needs to see the boy so he can take away all t...\n",
       "7                                   Sickly  goodnight\n",
       "8   Good morning driven w/out my ipod.  so sad. Bu...\n",
       "9   heyyy where'd my tweet go?  *shouts to @fusebo...\n",
       "10                               Oh no! Bill is dead!\n",
       "11  @ilovemakonnen damnit u just ruined the image ...\n",
       "12                                Working until 230am\n",
       "13                         has really bad headaches..\n",
       "14  watching Taylor Swift videos from YouTube on m...\n",
       "15  @sobeworld the 0 calorie ones are hard 2 find;...\n",
       "16  @itsjudytime ur so lucky!! I love summer!! unl...\n",
       "17           I missed the call from my boo.  Sad face\n",
       "18  bedtimeee tomorrow prepearing for the last wee...\n",
       "19                     I'm going to miss my apartment\n",
       "20  Weekends almost over  if only the weekdays wen...\n",
       "21  everyone please vote for @selenagomez for teen...\n",
       "22  At work... Meeting tonight but I'm kinda out o...\n",
       "23   batting average after today 538 befour today 600\n",
       "24  Chris Brown is scum ...  justice failed once a...\n",
       "25             @CeCeaKaDiMpLeZ don't sound so excited\n",
       "26            disappointed the didnt win teh glasses.\n",
       "27  @katiehutchison It hasn't been quite that long...\n",
       "28  Lloonngg asss dayy and its no where near over ...\n",
       "29  Watching my 13 year ild brother-in-law's baseb...\n",
       "30           sick  just hung out with cousins all day\n",
       "31  @ceskaholka Wow. four days! I get migraines fr...\n",
       "32                               Awww  @ColeTheCondor\n",
       "33  This train is taking so long. It stops at stat...\n",
       "34  Ow my eyes hurt from staring at this screen fo...\n",
       "35  @tylercaulfield no fevers\\nNose piercing got h...\n",
       "36  @Meg_Andruschak What?! Still no baby?  I hope ...\n",
       "37                                3.0 broke my iPhone\n",
       "38  wishing i could go back in time and go to texa...\n",
       "39  Geez....... hockey is over with till October. ...\n",
       "40                          may head to bed try sleep\n",
       "41  Time for some much needed sleep\\nthe boo says ...\n",
       "42  being sad about losing followers..i be oh so b...\n",
       "43  @Kristofer_Krack Oh man! You can't punish ME f...\n",
       "44  @Shesirawr @evvss pmnya baca aja  http://myloc...\n",
       "45                I don't think i like twitter so far\n",
       "46  7 games to 0 Mancala ass beating administered ...\n",
       "47  Next will be English class for kindy.  I wish ...\n",
       "48                       I wanted orange chicken too!\n",
       "49  @KezzieN you're not the only one.Here my MTV d...\n",
       "50  Boyfriend was all sad and gloomy last night.al...\n",
       "51  I am enjoying my time here but missing my husb...\n",
       "52                I had a really long scary nightmare\n",
       "53  @PatrickAvis Stretching and rest\\n@disobedient...\n",
       "54  @moregAAn I know... It just makes me sad. Who'...\n",
       "55  @jen_n_em The link sends me to my Fb home page...\n",
       "56  OMGGGG havent tweeted for so long  id just lik...\n",
       "57  @Dragonrider80 sounds painfull poor thing  yea...\n",
       "58  just found that last fm is no longer free radi...\n",
       "59  @nicholasbraun atleast you get to sleep all da...\n",
       "                                                  ...\n",
       "\n",
       "[50080 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Solution = https://docs.google.com/document/d/1QCnnupiJXQdMzv1E1Q8Y8EZ54-McyhOIKh1WFMi-yR0/edit\n",
    "import pandas as pd\n",
    "\n",
    "pos_df = pd.read_csv('data/pos_examples_PosSentiment.txt', header = None, names = ['text'], sep = '\\n')\n",
    "neg_df = pd.read_csv('data/neg_examples_NegSentiment.txt', header = None, names = ['text'], sep = '\\n')\n",
    "\n",
    "pos_df\n",
    "neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50064"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_neg = pd.read_csv('data/neg_examples_NegSentiment.txt', header = None, names = ['text'], sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td> @chief1972 not with my iPhone 1st generation I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td> @mandeev I can't go today.  Give them my love\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td> Ugh\\nHad some awesome unknown Belgian beer ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td> Told Fizul that 2 of my friends are coming. To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td>                          Disturbed by White Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td>                          Working on this fine day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td> needs to see the boy so he can take away all t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td>                                 Sickly  goodnight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td> Good morning driven w/out my ipod.  so sad. Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> heyyy where'd my tweet go?  *shouts to @fusebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>                              Oh no! Bill is dead!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> @ilovemakonnen damnit u just ruined the image ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>                               Working until 230am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>                        has really bad headaches..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> watching Taylor Swift videos from YouTube on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td> @sobeworld the 0 calorie ones are hard 2 find;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td> @itsjudytime ur so lucky!! I love summer!! unl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>          I missed the call from my boo.  Sad face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td> bedtimeee tomorrow prepearing for the last wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>                    I'm going to miss my apartment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td> Weekends almost over  if only the weekdays wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td> everyone please vote for @selenagomez for teen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td> At work... Meeting tonight but I'm kinda out o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>  batting average after today 538 befour today 600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td> Chris Brown is scum ...  justice failed once a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>            @CeCeaKaDiMpLeZ don't sound so excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>           disappointed the didnt win teh glasses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td> @katiehutchison It hasn't been quite that long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td> Lloonngg asss dayy and its no where near over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td> Watching my 13 year ild brother-in-law's baseb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>          sick  just hung out with cousins all day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td> @ceskaholka Wow. four days! I get migraines fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>                              Awww  @ColeTheCondor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td> This train is taking so long. It stops at stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td> Ow my eyes hurt from staring at this screen fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td> @tylercaulfield no fevers\\nNose piercing got h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td> @Meg_Andruschak What?! Still no baby?  I hope ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>                               3.0 broke my iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td> wishing i could go back in time and go to texa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td> Geez....... hockey is over with till October. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>                         may head to bed try sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td> Time for some much needed sleep\\nthe boo says ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td> being sad about losing followers..i be oh so b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td> @Kristofer_Krack Oh man! You can't punish ME f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td> @Shesirawr @evvss pmnya baca aja  http://myloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>               I don't think i like twitter so far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td> 7 games to 0 Mancala ass beating administered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td> Next will be English class for kindy.  I wish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>                      I wanted orange chicken too!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td> @KezzieN you're not the only one.Here my MTV d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td> Boyfriend was all sad and gloomy last night.al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td> I am enjoying my time here but missing my husb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>               I had a really long scary nightmare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td> @PatrickAvis Stretching and rest\\n@disobedient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td> @moregAAn I know... It just makes me sad. Who'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td> @jen_n_em The link sends me to my Fb home page...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td> OMGGGG havent tweeted for so long  id just lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td> @Dragonrider80 sounds painfull poor thing  yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td> just found that last fm is no longer free radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td> @nicholasbraun atleast you get to sleep all da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50082 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   @chief1972 not with my iPhone 1st generation I...\n",
       "1   @mandeev I can't go today.  Give them my love\\...\n",
       "2   Ugh\\nHad some awesome unknown Belgian beer ton...\n",
       "3   Told Fizul that 2 of my friends are coming. To...\n",
       "4                            Disturbed by White Light\n",
       "5                            Working on this fine day\n",
       "6   needs to see the boy so he can take away all t...\n",
       "7                                   Sickly  goodnight\n",
       "8   Good morning driven w/out my ipod.  so sad. Bu...\n",
       "9   heyyy where'd my tweet go?  *shouts to @fusebo...\n",
       "10                               Oh no! Bill is dead!\n",
       "11  @ilovemakonnen damnit u just ruined the image ...\n",
       "12                                Working until 230am\n",
       "13                         has really bad headaches..\n",
       "14  watching Taylor Swift videos from YouTube on m...\n",
       "15  @sobeworld the 0 calorie ones are hard 2 find;...\n",
       "16  @itsjudytime ur so lucky!! I love summer!! unl...\n",
       "17           I missed the call from my boo.  Sad face\n",
       "18  bedtimeee tomorrow prepearing for the last wee...\n",
       "19                     I'm going to miss my apartment\n",
       "20  Weekends almost over  if only the weekdays wen...\n",
       "21  everyone please vote for @selenagomez for teen...\n",
       "22  At work... Meeting tonight but I'm kinda out o...\n",
       "23   batting average after today 538 befour today 600\n",
       "24  Chris Brown is scum ...  justice failed once a...\n",
       "25             @CeCeaKaDiMpLeZ don't sound so excited\n",
       "26            disappointed the didnt win teh glasses.\n",
       "27  @katiehutchison It hasn't been quite that long...\n",
       "28  Lloonngg asss dayy and its no where near over ...\n",
       "29  Watching my 13 year ild brother-in-law's baseb...\n",
       "30           sick  just hung out with cousins all day\n",
       "31  @ceskaholka Wow. four days! I get migraines fr...\n",
       "32                               Awww  @ColeTheCondor\n",
       "33  This train is taking so long. It stops at stat...\n",
       "34  Ow my eyes hurt from staring at this screen fo...\n",
       "35  @tylercaulfield no fevers\\nNose piercing got h...\n",
       "36  @Meg_Andruschak What?! Still no baby?  I hope ...\n",
       "37                                3.0 broke my iPhone\n",
       "38  wishing i could go back in time and go to texa...\n",
       "39  Geez....... hockey is over with till October. ...\n",
       "40                          may head to bed try sleep\n",
       "41  Time for some much needed sleep\\nthe boo says ...\n",
       "42  being sad about losing followers..i be oh so b...\n",
       "43  @Kristofer_Krack Oh man! You can't punish ME f...\n",
       "44  @Shesirawr @evvss pmnya baca aja  http://myloc...\n",
       "45                I don't think i like twitter so far\n",
       "46  7 games to 0 Mancala ass beating administered ...\n",
       "47  Next will be English class for kindy.  I wish ...\n",
       "48                       I wanted orange chicken too!\n",
       "49  @KezzieN you're not the only one.Here my MTV d...\n",
       "50  Boyfriend was all sad and gloomy last night.al...\n",
       "51  I am enjoying my time here but missing my husb...\n",
       "52                I had a really long scary nightmare\n",
       "53  @PatrickAvis Stretching and rest\\n@disobedient...\n",
       "54  @moregAAn I know... It just makes me sad. Who'...\n",
       "55  @jen_n_em The link sends me to my Fb home page...\n",
       "56  OMGGGG havent tweeted for so long  id just lik...\n",
       "57  @Dragonrider80 sounds painfull poor thing  yea...\n",
       "58  just found that last fm is no longer free radi...\n",
       "59  @nicholasbraun atleast you get to sleep all da...\n",
       "                                                  ...\n",
       "\n",
       "[50082 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data = COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "##### load training data\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "###read tagged sentiment Tweets\n",
    "with open('data/pos_examples_PosSentiment.txt', 'r') as f:\n",
    "    pos_tweets = f.readlines()\n",
    "\n",
    "with open('data/neg_examples_NegSentiment.txt', 'r') as f:\n",
    "    neg_tweets = f.readlines()\n",
    "    \n",
    "class_label = 0\n",
    "train_pos = pd.DataFrame(pos_tweets, columns = ['text'])\n",
    "X0 = train_pos.text\n",
    "y0 = np.full(shape=len(X0), fill_value=class_label)\n",
    "\n",
    "###create random 80-20 split\n",
    "rows = random.sample(X0.index, int(0.8*len(X0)))\n",
    "X0_80 = X0.ix[rows]\n",
    "X0_20 = X0.drop(rows)\n",
    "y0_80 = y0[:int(0.8*len(X0))]\n",
    "y0_20 = y0[int(0.8*len(X0)):]\n",
    "###\n",
    "\n",
    "class_label = 1\n",
    "train_neg = pd.DataFrame(neg_tweets, columns = ['text'])\n",
    "X1 = train_neg.text\n",
    "y1 = np.full(shape=len(X1), fill_value=class_label)\n",
    "\n",
    "###create random 80-20 split\n",
    "rows = random.sample(X1.index, int(0.8*len(X1)))\n",
    "X1_80 = X1.ix[rows]\n",
    "X1_20 = X1.drop(rows)\n",
    "y1_80 = y1[:int(0.8*len(X1))]\n",
    "y1_20 = y1[int(0.8*len(X1)):]\n",
    "###\n",
    "\n",
    "X_train = pd.concat((X0_80,X1_80))\n",
    "y_train = np.concatenate((y0_80, y1_80))\n",
    "\n",
    "X_holdout = pd.concat((X0_20,X1_20))\n",
    "y_holdout = np.concatenate((y0_20, y1_20))\n",
    "\n",
    "### load testing data\n",
    "\n",
    "###read tagged sentiment Tweets\n",
    "with open('data/pos_examples_happy.txt', 'r') as f:\n",
    "    pos_tweets = f.readlines()\n",
    "\n",
    "with open('data/neg_examples_sad.txt', 'r') as f:\n",
    "    neg_tweets = f.readlines()\n",
    "    \n",
    "import numpy as np\n",
    "class_label = 0\n",
    "train_pos = pd.DataFrame(pos_tweets, columns = ['text'])\n",
    "X0 = train_pos.text\n",
    "y0 = np.full(shape=len(X0), fill_value=class_label)\n",
    "\n",
    "class_label = 1\n",
    "train_neg = pd.DataFrame(neg_tweets, columns = ['text'])\n",
    "X1 = train_neg.text\n",
    "y1 = np.full(shape=len(X1), fill_value=class_label)\n",
    "\n",
    "X_test = pd.concat((X0,X1))\n",
    "y_test = np.concatenate((y0, y1))\n",
    "\n",
    "###\n",
    "print \"Loading data = COMPLETE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pipeline = DONE!\n"
     ]
    }
   ],
   "source": [
    "### build pipeline; fit train; predict on test\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "##vectorizer arguments blah!\n",
    "\n",
    "tokenizer=None#word_tokenize\n",
    "stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "ngram_range=(1, 3)\n",
    "lowercase=True\n",
    "max_features=5000\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "    \n",
    "###create vectorizer\n",
    "vectorizer = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "                               stop_words=stop_words,\n",
    "                               ngram_range=ngram_range,\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', vectorizer),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(alpha=0.01)),\n",
    "#                     ('clf', LinearSVC(C=0.1)),\n",
    "#                     (\"clf\", LogisticRegression(fit_intercept=False))\n",
    "#         (\"clf\", RandomForestClassifier(n_estimators=50, max_features=\"auto\", criterion=\"entropy\", n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "# text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "# predicted = text_clf.predict(X_test)\n",
    "# np.mean(predicted == y_test)\n",
    "\n",
    "print \"Building pipeline = DONE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting on train data = DONE!\n"
     ]
    }
   ],
   "source": [
    "###fit training data\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "print \"Fitting on train data = DONE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.729125\n",
      "Predict on holdout data = DONE!\n"
     ]
    }
   ],
   "source": [
    "###evaluate model on holdout set and print confusion matrix\n",
    "predicted = text_clf.predict(X_holdout)\n",
    "print np.mean(predicted == y_holdout)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print \"Predict on holdout data = DONE!\"\n",
    "total_confusion_matrix = confusion_matrix(y_holdout, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731591448931 0.7238 0.727674868676 0.729125\n"
     ]
    }
   ],
   "source": [
    "###get performance metrics\n",
    "# accuracy = np.mean(y_holdout == predicted)\n",
    "accuracy = (y_holdout,predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_holdout, predicted, average='binary', pos_label=0)\n",
    "print precision, recall, fscore, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14476, 5524, 5311, 14689)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = total_confusion_matrix[0][0]\n",
    "fn = total_confusion_matrix[0][1]\n",
    "fp = total_confusion_matrix[1][0]\n",
    "tn = total_confusion_matrix[1][1]\n",
    "\n",
    "tp, fn, fp, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7315914489311164, 0.7238, 0.729125, 0.7276748686756981)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = float(tp)/(tp+fp)\n",
    "recall = float(tp)/(tp+fn)\n",
    "accuracy = float(tp+tn)/(tp+tn+fp+fn)\n",
    "fscore = 2.0*precision*recall/(precision+recall)\n",
    "precision, recall, accuracy, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error='ignore',\n",
       "        dtype=<type 'numpy.float64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None,\n",
       "        stop_words=['i', '...enizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952987598647\n",
      "Predict on test data = DONE!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[17305,   435],\n",
       "       [ 1233, 16507]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict on test data and print confusion matrix\n",
    "predicted = text_clf.predict(X_test)\n",
    "print np.mean(predicted == y_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print \"Predict on test data = DONE!\"\n",
    "confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "[[11591  4283]\n",
      " [ 4317 11809]]\n",
      "Accuracy =  0.73125\n",
      "Fold  2\n",
      "[[11231  4909]\n",
      " [ 3806 12054]]\n",
      "Accuracy =  0.72765625\n",
      "Fold  3\n",
      "[[11433  4470]\n",
      " [ 4256 11841]]\n",
      "Accuracy =  0.7273125\n",
      "Fold  4\n",
      "[[11050  5079]\n",
      " [ 3777 12094]]\n",
      "Accuracy =  0.72325\n",
      "Fold  5\n",
      "[[11529  4425]\n",
      " [ 4336 11710]]\n",
      "Accuracy =  0.72621875\n",
      "FINAL CONFUSION MATRIX\n",
      "[[ 56834.  23166.]\n",
      " [ 20492.  59508.]]\n"
     ]
    }
   ],
   "source": [
    "#### 5-fold cross-validation: NB\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "total_confusion_matrix = np.zeros((2, 2))\n",
    "count = 0\n",
    "\n",
    "kf = KFold(len(X_train), n_folds=5, shuffle=True, random_state=42)\n",
    "for train, test in kf:\n",
    "    ##split into cv- train and test:\n",
    "    count += 1\n",
    "    print \"Fold \", count \n",
    "    X_CVtrain, y_CVtrain, X_CVtest, y_CVtest = X_train.values[train], y_train[train], X_train.values[test], y_train[test]\n",
    "    \n",
    "    ###fit on cv-train:\n",
    "    cv = text_clf.fit(X_CVtrain, y_CVtrain)\n",
    "\n",
    "    ## predict on cv-test\n",
    "    predicted = cv.predict(X_CVtest)\n",
    "    \n",
    "    ###get confusion matric\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "    current_confusion_matrix = confusion_matrix(y_CVtest, predicted)\n",
    "    print current_confusion_matrix\n",
    "    print \"Accuracy = \", np.mean(y_CVtest == predicted)\n",
    "    total_confusion_matrix += current_confusion_matrix\n",
    "\n",
    "print \"FINAL CONFUSION MATRIX\"\n",
    "print total_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "[[11373  4501]\n",
      " [ 4269 11857]]\n",
      "Accuracy =  0.7259375\n",
      "Fold  2\n",
      "[[11230  4910]\n",
      " [ 3860 12000]]\n",
      "Accuracy =  0.7259375\n",
      "Fold  3\n",
      "[[11490  4413]\n",
      " [ 4271 11826]]\n",
      "Accuracy =  0.728625\n",
      "Fold  4\n",
      "[[11173  4956]\n",
      " [ 3740 12131]]\n",
      "Accuracy =  0.72825\n",
      "Fold  5\n",
      "[[11527  4427]\n",
      " [ 4304 11742]]\n",
      "Accuracy =  0.72715625\n",
      "FINAL CONFUSION MATRIX\n",
      "[[ 56793.  23207.]\n",
      " [ 20444.  59556.]]\n"
     ]
    }
   ],
   "source": [
    "#### 5-fold cross-validation: SVC\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "total_confusion_matrix = np.zeros((2, 2))\n",
    "count = 0\n",
    "\n",
    "kf = KFold(len(X_train), n_folds=5, shuffle=True, random_state=42)\n",
    "for train, test in kf:\n",
    "    ##split into cv- train and test:\n",
    "    count += 1\n",
    "    print \"Fold \", count \n",
    "    X_CVtrain, y_CVtrain, X_CVtest, y_CVtest = X_train.values[train], y_train[train], X_train.values[test], y_train[test]\n",
    "    \n",
    "    ###fit on cv-train:\n",
    "    cv = text_clf.fit(X_CVtrain, y_CVtrain)\n",
    "\n",
    "    ## predict on cv-test\n",
    "    predicted = cv.predict(X_CVtest)\n",
    "    \n",
    "    ###get confusion matric\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "    current_confusion_matrix = confusion_matrix(y_CVtest, predicted)\n",
    "    print current_confusion_matrix\n",
    "    print \"Accuracy = \", np.mean(y_CVtest == predicted)\n",
    "    total_confusion_matrix += current_confusion_matrix\n",
    "\n",
    "print \"FINAL CONFUSION MATRIX\"\n",
    "print total_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Confusion matrix =  [ tp fn]\n",
    "#                    [ fp tn]\n",
    "tp = total_confusion_matrix[0][0]\n",
    "fn = total_confusion_matrix[0][1]\n",
    "fp = total_confusion_matrix[1][0]\n",
    "tn = total_confusion_matrix[1][1]\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "fscore = 2*precision*recall/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56793.,  23207.],\n",
       "       [ 20444.,  59556.]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56793.0, 20444.0, 59556.0, 23207.0)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.73530820720639067, 0.70991249999999995, 0.72718125, 0.72238722438102987)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, accuracy, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.72620446533490013, 0.73177115792097724, 0.72897718454136284, None)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_CVtest, predicted, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_CVtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5524"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB - holdout\n",
      "MNB 0.728148036708 0.726 0.727072431837 0.727475\n",
      "LinearSVC - holdout\n",
      "LinearSVC 0.71397616468 0.7908 0.750427026001 0.737\n",
      "RandomForest - holdout\n",
      "randomforest 0.725082146769 0.7613 0.742749823166 0.736325\n",
      "Prediction on holdout = DONE!\n"
     ]
    }
   ],
   "source": [
    "### build pipeline; fit train; predict on holdout - MNB, SVC, RF\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "##vectorizer arguments blah!\n",
    "\n",
    "tokenizer=None#word_tokenize\n",
    "stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "ngram_range=(1, 3)\n",
    "lowercase=True\n",
    "max_features=5000\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "    \n",
    "###create vectorizer\n",
    "vectorizer = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "                               stop_words=stop_words,\n",
    "                               ngram_range=ngram_range,\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "##set best parameters\n",
    "alpha = 0.1\n",
    "C = 1.0\n",
    "n_estimators = 100\n",
    "##\n",
    "\n",
    "classif = \"MNB\"\n",
    "print \"Multinomial NB - holdout\"\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', vectorizer),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(alpha=alpha)),\n",
    "#                     ('clf', LinearSVC(C=0.1)),\n",
    "#                     (\"clf\", LogisticRegression(fit_intercept=False))\n",
    "#         (\"clf\", RandomForestClassifier(n_estimators=50, max_features=\"auto\", criterion=\"entropy\", n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_holdout)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_holdout,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_holdout, predicted, average='binary', pos_label=0)\n",
    "print classif, precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "\n",
    "###\n",
    "\n",
    "classif = \"LinearSVC\"\n",
    "print \"LinearSVC - holdout\"\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', vectorizer),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('clf', MultinomialNB(alpha=alpha)),\n",
    "                    ('clf', LinearSVC(C=C)),\n",
    "#                     (\"clf\", LogisticRegression(fit_intercept=False))\n",
    "#         (\"clf\", RandomForestClassifier(n_estimators=50, max_features=\"auto\", criterion=\"entropy\", n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_holdout)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_holdout,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_holdout, predicted, average='binary', pos_label=0)\n",
    "print classif, precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "###\n",
    "\n",
    "classif = \"randomforest\"\n",
    "print \"RandomForest - holdout\"\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', vectorizer),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('clf', MultinomialNB(alpha=alpha)),\n",
    "#                     ('clf', LinearSVC(C=C)),\n",
    "#                     (\"clf\", LogisticRegression(fit_intercept=False))\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=n_estimators, max_features=\"auto\", criterion=\"entropy\", n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_holdout)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_holdout,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_holdout, predicted, average='binary', pos_label=0)\n",
    "print classif, precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "###\n",
    "print \"Prediction on holdout = DONE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB - Test\n",
      "MNB 0.934336894356 0.976155580609 0.954788553785 0.953776775648\n",
      "LinearSVC - Test\n",
      "LinearSVC 0.963107881498 0.971251409245 0.967162503508 0.96702367531\n",
      "RandomForest - Test\n",
      "randomforest 0.976786025187 0.948759864713 0.962568985731 0.963105975197\n",
      "Prediction on Test = DONE!\n"
     ]
    }
   ],
   "source": [
    "### build pipeline; fit TRAIN; predict on TEST - MNB, SVC, RF\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "##vectorizer arguments blah!\n",
    "\n",
    "tokenizer=None#word_tokenize\n",
    "stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "ngram_range=(1, 3)\n",
    "lowercase=True\n",
    "max_features=5000\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "    \n",
    "###create vectorizer\n",
    "vectorizer = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "                               stop_words=stop_words,\n",
    "                               ngram_range=ngram_range,\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "##set best hyperparameters\n",
    "alpha = 0.1\n",
    "C = 1.0\n",
    "n_estimators = 100\n",
    "##\n",
    "\n",
    "classif = \"MNB\"\n",
    "print \"Multinomial NB - Test\"\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', vectorizer),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(alpha=alpha)),\n",
    "#                     ('clf', LinearSVC(C=0.1)),\n",
    "#                     (\"clf\", LogisticRegression(fit_intercept=False))\n",
    "#         (\"clf\", RandomForestClassifier(n_estimators=50, max_features=\"auto\", criterion=\"entropy\", n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print classif, precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "\n",
    "###\n",
    "\n",
    "classif = \"LinearSVC\"\n",
    "print \"LinearSVC - Test\"\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', vectorizer),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('clf', MultinomialNB(alpha=alpha)),\n",
    "                    ('clf', LinearSVC(C=C)),\n",
    "#                     (\"clf\", LogisticRegression(fit_intercept=False))\n",
    "#         (\"clf\", RandomForestClassifier(n_estimators=50, max_features=\"auto\", criterion=\"entropy\", n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print classif, precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "###\n",
    "\n",
    "classif = \"randomforest\"\n",
    "print \"RandomForest - Test\"\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', vectorizer),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('clf', MultinomialNB(alpha=alpha)),\n",
    "#                     ('clf', LinearSVC(C=C)),\n",
    "#                     (\"clf\", LogisticRegression(fit_intercept=False))\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=n_estimators, max_features=\"auto\", criterion=\"entropy\", n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print classif, precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "###\n",
    "print \"Prediction on Test = DONE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###print top 5000 features \n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "##vectorizer arguments blah!\n",
    "\n",
    "tokenizer=None#word_tokenize\n",
    "stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "stop_words.append('rt')\n",
    "stop_words.append('com')\n",
    "stop_words.append('www')\n",
    "stop_words.append('http')\n",
    "stop_words.append('https')\n",
    "stop_words.append('twitter')\n",
    "ngram_range=(1, 3)\n",
    "lowercase=True\n",
    "max_features=5000\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "\n",
    "###create vectorizer\n",
    "vectorizer = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "                               stop_words=stop_words,\n",
    "                               ngram_range=ngram_range,\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "train_fit = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'fit': 1516,\n",
       " u'fix': 1518,\n",
       " u'thanks everyone': 4286,\n",
       " u'sorted': 4000,\n",
       " u'kno': 2417,\n",
       " u'knw': 2438,\n",
       " u'staring': 4053,\n",
       " u'become': 414,\n",
       " u'omg love': 3155,\n",
       " u'runs': 3690,\n",
       " u'nuggets': 3105,\n",
       " u'exciting': 1356,\n",
       " u'almost done': 189,\n",
       " u'think gonna': 4322,\n",
       " u'physics': 3300,\n",
       " u'camera': 664,\n",
       " u'could help': 908,\n",
       " u'tweeterfollow add everyone': 4529,\n",
       " u'tell annoying': 4255,\n",
       " u'effing': 1254,\n",
       " u'omg': 3154,\n",
       " u'failing': 1384,\n",
       " u'joeymcintyre': 2336,\n",
       " u'august': 309,\n",
       " u'considering': 875,\n",
       " u'hour': 2142,\n",
       " u'sucks': 4149,\n",
       " u'perry': 3278,\n",
       " u'coke': 821,\n",
       " u'things going': 4314,\n",
       " u'andy': 211,\n",
       " u'today': 4401,\n",
       " u'figure': 1476,\n",
       " u'deserve': 1090,\n",
       " u'apartment': 246,\n",
       " u'time get': 4375,\n",
       " u'attention': 306,\n",
       " u'shirt': 3837,\n",
       " u'iphone': 2271,\n",
       " u'tweetdeck': 4522,\n",
       " u'lost please': 2661,\n",
       " u'yellow': 4956,\n",
       " u'wisdom': 4819,\n",
       " u'tastes': 4229,\n",
       " u'gone': 1774,\n",
       " u'gona': 1773,\n",
       " u'garden': 1628,\n",
       " u'atlanta': 298,\n",
       " u'birds': 477,\n",
       " u'window': 4808,\n",
       " u'felt': 1464,\n",
       " u'prepare': 3408,\n",
       " u'fool': 1555,\n",
       " u'food': 1553,\n",
       " u'foot': 1556,\n",
       " u'trees': 4475,\n",
       " u'rolls': 3669,\n",
       " u'cupcakes': 969,\n",
       " u'candy': 673,\n",
       " u'th': 4278,\n",
       " u'glad like': 1708,\n",
       " u'picking': 3305,\n",
       " u'get rid': 1664,\n",
       " u'wifey': 4801,\n",
       " u'helping': 2042,\n",
       " u'starting': 4058,\n",
       " u'nervous': 3009,\n",
       " u'forward': 1568,\n",
       " u'everyone train': 1335,\n",
       " u'center': 719,\n",
       " u'oops': 3177,\n",
       " u'tests': 4270,\n",
       " u'jonas': 2346,\n",
       " u'rate': 3513,\n",
       " u'hehehe': 2031,\n",
       " u'beast': 406,\n",
       " u'jonas brothers': 2347,\n",
       " u'raining': 3505,\n",
       " u'next month': 3042,\n",
       " u'glad see': 1709,\n",
       " u'one week': 3166,\n",
       " u'wrk': 4917,\n",
       " u'still feeling': 4086,\n",
       " u'hilarious': 2060,\n",
       " u'la': 2445,\n",
       " u'lt': 2696,\n",
       " u'checking': 750,\n",
       " u'thingy': 4315,\n",
       " u'cars': 697,\n",
       " u'card': 689,\n",
       " u'care': 691,\n",
       " u'wendy': 4774,\n",
       " u'fairy': 1388,\n",
       " u'rolling': 3668,\n",
       " u'shaking': 3820,\n",
       " u'based': 386,\n",
       " u'wise': 4821,\n",
       " u'field': 1473,\n",
       " u'bucks': 609,\n",
       " u'thanks man': 4294,\n",
       " u'vids': 4637,\n",
       " u'make happy': 2730,\n",
       " u'dude': 1213,\n",
       " u'reviews': 3631,\n",
       " u'thing': 4310,\n",
       " u'think': 4316,\n",
       " u'jimmy': 2330,\n",
       " u'feeling better': 1448,\n",
       " u'30am': 63,\n",
       " u'hearing': 2019,\n",
       " u'hunt': 2170,\n",
       " u'hung': 2166,\n",
       " u'accounts': 114,\n",
       " u'crush': 960,\n",
       " u'style': 4141,\n",
       " u'nights': 3068,\n",
       " u'nighty': 3069,\n",
       " u'problems': 3436,\n",
       " u'lots fun': 2666,\n",
       " u'theory': 4306,\n",
       " u'trending': 4477,\n",
       " u'busy': 633,\n",
       " u'bust': 631,\n",
       " u'ang': 213,\n",
       " u'funeral': 1616,\n",
       " u'ridiculous': 3639,\n",
       " u'note': 3093,\n",
       " u'ironing': 2281,\n",
       " u'ago': 152,\n",
       " u'age': 150,\n",
       " u'literally': 2590,\n",
       " u'phones': 3293,\n",
       " u'7th': 91,\n",
       " u'wanna know': 4683,\n",
       " u'lack': 2448,\n",
       " u'like see': 2565,\n",
       " u'tried': 4481,\n",
       " u'actually': 126,\n",
       " u'grocery': 1886,\n",
       " u'gets better': 1675,\n",
       " u'lauren': 2495,\n",
       " u'presents': 3413,\n",
       " u'totally agree': 4451,\n",
       " u'finally': 1488,\n",
       " u'twurl nl': 4552,\n",
       " u'everybody': 1331,\n",
       " u'girl': 1696,\n",
       " u'living': 2601,\n",
       " u'stupid': 4140,\n",
       " u'bags': 367,\n",
       " u'different': 1117,\n",
       " u'lolol': 2627,\n",
       " u'keys': 2386,\n",
       " u'chicago': 762,\n",
       " u'looks': 2649,\n",
       " u'received': 3571,\n",
       " u'phone': 3291,\n",
       " u'hope great': 2121,\n",
       " u'birthday': 478,\n",
       " u'two weeks': 4549,\n",
       " u'ha ha ha': 1920,\n",
       " u'aaron': 99,\n",
       " u'passed': 3241,\n",
       " u'longest': 2638,\n",
       " u'goodness': 1823,\n",
       " u'best friends': 443,\n",
       " u'scream': 3751,\n",
       " u'great song': 1878,\n",
       " u'wordpress': 4864,\n",
       " u'working': 4886,\n",
       " u'internet': 2266,\n",
       " u'please tell': 3350,\n",
       " u'nothin': 3096,\n",
       " u'full': 1607,\n",
       " u'also': 195,\n",
       " u'sunny': 4168,\n",
       " u'clients': 800,\n",
       " u'process': 3438,\n",
       " u'full day': 1608,\n",
       " u'able get': 102,\n",
       " u'cutie': 980,\n",
       " u'pack': 3206,\n",
       " u'friendly': 1591,\n",
       " u'smoking': 3935,\n",
       " u'tells': 4259,\n",
       " u'hooray': 2108,\n",
       " u'filled': 1481,\n",
       " u'cant find': 679,\n",
       " u'pissed': 3320,\n",
       " u'awesome day': 325,\n",
       " u'2night': 58,\n",
       " u'shape': 3824,\n",
       " u'tsk': 4500,\n",
       " u'orlando': 3192,\n",
       " u'awh': 327,\n",
       " u'urgh': 4600,\n",
       " u'competition': 853,\n",
       " u'day everyone': 1027,\n",
       " u'happier': 1960,\n",
       " u'holiday': 2079,\n",
       " u'opened': 3179,\n",
       " u'steph': 4077,\n",
       " u'always': 197,\n",
       " u'preparing': 3410,\n",
       " u'surely': 4178,\n",
       " u'studying': 4137,\n",
       " u'sister': 3894,\n",
       " u'really wanted': 3565,\n",
       " u'could come': 905,\n",
       " u'evil': 1341,\n",
       " u'jon kate': 2345,\n",
       " u'amp kate': 207,\n",
       " u'wont': 4852,\n",
       " u'wish luck': 4827,\n",
       " u'im missing': 2217,\n",
       " u'homie': 2098,\n",
       " u'fuckin': 1605,\n",
       " u'shame': 3822,\n",
       " u'delete': 1074,\n",
       " u'going try': 1766,\n",
       " u'cancel': 669,\n",
       " u'bank': 380,\n",
       " u'private': 3431,\n",
       " u'wont let': 4853,\n",
       " u'philippines': 3289,\n",
       " u'want know': 4693,\n",
       " u'falls': 1396,\n",
       " u'taylor': 4235,\n",
       " u'idiot': 2192,\n",
       " u'xoxo': 4929,\n",
       " u'fed': 1429,\n",
       " u'\\xf0\\xbe\\xf0': 4999,\n",
       " u'thankful': 4284,\n",
       " u'city': 785,\n",
       " u'bunny': 623,\n",
       " u'upgrade': 4591,\n",
       " u'favorites': 1423,\n",
       " u'bring': 582,\n",
       " u'say hi': 3728,\n",
       " u'assignments': 294,\n",
       " u'laurenconrad': 2496,\n",
       " u'quit': 3483,\n",
       " u'quiz': 3485,\n",
       " u'pic': 3302,\n",
       " u'pix': 3322,\n",
       " u'like crazy': 2554,\n",
       " u'tacos': 4208,\n",
       " u'please please': 3348,\n",
       " u'awkward': 329,\n",
       " u'burned': 626,\n",
       " u'prepared': 3409,\n",
       " u'tracecyrus': 4460,\n",
       " u'one hour': 3161,\n",
       " u'badly': 365,\n",
       " u'outside': 3198,\n",
       " u'brian': 577,\n",
       " u'necklace': 2990,\n",
       " u'billy': 471,\n",
       " u'bills': 470,\n",
       " u'july': 2361,\n",
       " u'rained': 3504,\n",
       " u'knew': 2415,\n",
       " u'knee': 2413,\n",
       " u'stuck head': 4129,\n",
       " u'oh well': 3140,\n",
       " u'load': 2606,\n",
       " u'eatin': 1241,\n",
       " u'balls': 375,\n",
       " u'cranky': 934,\n",
       " u'lucky': 2703,\n",
       " u'ebay': 1243,\n",
       " u'worry': 4894,\n",
       " u'\\xbd\\xef \\xbd\\xef \\xbd\\xef': 4996,\n",
       " u'teaching': 4244,\n",
       " u'ignore': 2196,\n",
       " u'vista': 4646,\n",
       " u'massage': 2774,\n",
       " u'finishing': 1506,\n",
       " u'everyday': 1332,\n",
       " u'disappointed': 1126,\n",
       " u'csi': 963,\n",
       " u'giant': 1691,\n",
       " u'wish going': 4825,\n",
       " u'going school': 1761,\n",
       " u'good movie': 1803,\n",
       " u'often': 3127,\n",
       " u'rest peace': 3620,\n",
       " u'plain': 3326,\n",
       " u'good know': 1797,\n",
       " u'cracked': 932,\n",
       " u'tummy hurts': 4508,\n",
       " u'sorry missed': 3997,\n",
       " u'toilet': 4419,\n",
       " u'booked': 529,\n",
       " u'im hungry': 2216,\n",
       " u'generation': 1638,\n",
       " u'cleaned': 791,\n",
       " u'rip': 3647,\n",
       " u'rio': 3646,\n",
       " u'rid': 3637,\n",
       " u'pants': 3224,\n",
       " u'thanks much': 4295,\n",
       " u'quot quot': 3492,\n",
       " u'feeling': 1447,\n",
       " u'nicely': 3053,\n",
       " u'lots': 2665,\n",
       " u'id': 2189,\n",
       " u'getting ready': 1682,\n",
       " u'insane': 2252,\n",
       " u'bing': 473,\n",
       " u'watching tv': 4728,\n",
       " u'hope feel better': 2115,\n",
       " u'crack': 931,\n",
       " u'yeah': 4948,\n",
       " u'year': 4951,\n",
       " u'hurts': 2175,\n",
       " u'backup': 357,\n",
       " u'grand': 1864,\n",
       " u'could make': 909,\n",
       " u'third': 4335,\n",
       " u'every time': 1329,\n",
       " u'phil': 3288,\n",
       " u'awhile': 328,\n",
       " u'lunch': 2704,\n",
       " u'studies': 4134,\n",
       " u'lol wish': 2625,\n",
       " u'recommendation': 3577,\n",
       " u'farrah': 1408,\n",
       " u'excellent': 1352,\n",
       " u'celebs': 716,\n",
       " u'know right': 2432,\n",
       " u'jokes': 2343,\n",
       " u'adventure': 143,\n",
       " u'like new': 2561,\n",
       " u'sold': 3956,\n",
       " u'whilst': 4787,\n",
       " u'april': 263,\n",
       " u'joining': 2341,\n",
       " u'im happy': 2215,\n",
       " u'keeps': 2380,\n",
       " u'date': 1012,\n",
       " u'data': 1011,\n",
       " u'take': 4211,\n",
       " u'going shopping': 1763,\n",
       " u'ace': 115,\n",
       " u'act': 121,\n",
       " u'edition': 1249,\n",
       " u'gonna take': 1782,\n",
       " u'school tomorrow': 3743,\n",
       " u'back home': 348,\n",
       " u'space': 4015,\n",
       " u'pub': 3458,\n",
       " u'put': 3472,\n",
       " u'pup': 3465,\n",
       " u'terminator': 4265,\n",
       " u'auto': 314,\n",
       " u'make feel better': 2729,\n",
       " u'maybe': 2787,\n",
       " u'peanut butter': 3258,\n",
       " u'brunch': 603,\n",
       " u'give': 1701,\n",
       " u'gt lt': 1900,\n",
       " u'pink': 3317,\n",
       " u'ping': 3316,\n",
       " u'father day': 1415,\n",
       " u'going make': 1758,\n",
       " u'mornings': 2915,\n",
       " u'strawberry': 4119,\n",
       " u'sooooooo': 3991,\n",
       " u'light': 2549,\n",
       " u'pride': 3426,\n",
       " u'rockin': 3661,\n",
       " u'apart': 245,\n",
       " u'busy day': 635,\n",
       " u'realise': 3530,\n",
       " u'better soon': 453,\n",
       " u'hardly': 1985,\n",
       " u'clean room': 790,\n",
       " u'oo': 3171,\n",
       " u'ol': 3149,\n",
       " u'ok': 3147,\n",
       " u'oh': 3128,\n",
       " u'oz': 3204,\n",
       " u'ow': 3202,\n",
       " u'os': 3193,\n",
       " u'liverpool': 2599,\n",
       " u'woman': 4845,\n",
       " u'texts': 4276,\n",
       " u'fucking': 1606,\n",
       " u'warning': 4711,\n",
       " u'planning': 3331,\n",
       " u'easier': 1234,\n",
       " u'sigh': 3871,\n",
       " u'sign': 3873,\n",
       " u'wicked': 4797,\n",
       " u'freezing': 1581,\n",
       " u'alert': 178,\n",
       " u'partying': 3239,\n",
       " u'blackberry': 492,\n",
       " u'happy mothers': 1975,\n",
       " u'2010': 41,\n",
       " u'laying bed': 2501,\n",
       " u'well today': 4772,\n",
       " u'katyperry': 2377,\n",
       " u'way get': 4737,\n",
       " u'woohoo': 4857,\n",
       " u'horror': 2131,\n",
       " u'epic fail': 1298,\n",
       " u'go home': 1730,\n",
       " u'see guys': 3773,\n",
       " u'forever': 1561,\n",
       " u'work hours': 4873,\n",
       " u'started': 4057,\n",
       " u'crossed': 956,\n",
       " u'management': 2747,\n",
       " u'slowly': 3923,\n",
       " u'emailed': 1266,\n",
       " u'shop': 3847,\n",
       " u'shot': 3853,\n",
       " u'show': 3859,\n",
       " u'shoe': 3843,\n",
       " u'two': 4546,\n",
       " u'going away': 1747,\n",
       " u'haha yes': 1929,\n",
       " u'pineapple': 3315,\n",
       " u'lonely': 2630,\n",
       " u'kills': 2397,\n",
       " u'twitterberry': 4541,\n",
       " u'bacon': 358,\n",
       " u'feel good': 1437,\n",
       " u'suck': 4147,\n",
       " u'wut': 4923,\n",
       " u'really feel': 3540,\n",
       " u'warped': 4712,\n",
       " u'oh wait': 3139,\n",
       " u'etc': 1310,\n",
       " u'told': 4420,\n",
       " u'word': 4863,\n",
       " u'wore': 4866,\n",
       " u'work': 4867,\n",
       " u'toronto': 4448,\n",
       " u'youu': 4978,\n",
       " u'finally done': 1489,\n",
       " u'mcdonalds': 2790,\n",
       " u'mentioned': 2817,\n",
       " u'group': 1890,\n",
       " u'thanks followfriday': 4289,\n",
       " u'suppose': 4175,\n",
       " u'getting ready work': 1684,\n",
       " u'burger': 624,\n",
       " u'fine': 1499,\n",
       " u'find': 1495,\n",
       " u'flags': 1522,\n",
       " u'lines': 2578,\n",
       " u'cutting': 982,\n",
       " u'back bed': 347,\n",
       " u'metal': 2823,\n",
       " u'laptop': 2465,\n",
       " u'feeling really': 1452,\n",
       " u'stream': 4120,\n",
       " u'\\xe0\\xb9': 4997,\n",
       " u'far': 1405,\n",
       " u'fav': 1419,\n",
       " u'fat': 1413,\n",
       " u'wild': 4804,\n",
       " u'shipping': 3836,\n",
       " u'wishing could': 4834,\n",
       " u'book': 528,\n",
       " u'booo': 532,\n",
       " u'china': 771,\n",
       " u'first time': 1513,\n",
       " u'alice': 181,\n",
       " u'tr im': 4459,\n",
       " u'replied': 3606,\n",
       " u'replies': 3607,\n",
       " u'smiling': 3932,\n",
       " u'ugh': 4559,\n",
       " u'tryin': 4493,\n",
       " u'never thought': 3018,\n",
       " u'scotland': 3748,\n",
       " u'wouldnt': 4910,\n",
       " u'add everyone': 131,\n",
       " u'home': 2086,\n",
       " u'get ready': 1662,\n",
       " u'making': 2739,\n",
       " u'worries': 4893,\n",
       " u'shattered': 3827,\n",
       " u'laid': 2453,\n",
       " u'really tired': 3561,\n",
       " u'epic': 1297,\n",
       " u'ellen': 1262,\n",
       " u'honor': 2103,\n",
       " u'cha': 728,\n",
       " u'chi': 761,\n",
       " u'please come': 3343,\n",
       " u'happens': 1959,\n",
       " u'would': 4899,\n",
       " u'news': 3038,\n",
       " u'burnt': 628,\n",
       " u'spirit': 4031,\n",
       " u'wife': 4800,\n",
       " u'opening': 3180,\n",
       " u'perhaps': 3276,\n",
       " u'respond': 3616,\n",
       " u'dannymcfly': 1004,\n",
       " u'sunday morning': 4165,\n",
       " u'work work work': 4883,\n",
       " u'wondering': 4850,\n",
       " u'someone else': 3964,\n",
       " u'finished watching': 1505,\n",
       " u'failed': 1383,\n",
       " u'mood': 2905,\n",
       " u'twins': 4537,\n",
       " u'wearing': 4745,\n",
       " u'sleep last night': 3913,\n",
       " u'love one': 2680,\n",
       " u'comes': 836,\n",
       " u'media': 2798,\n",
       " u'fruit': 1598,\n",
       " u'central': 720,\n",
       " u'moved': 2926,\n",
       " u'going well': 1768,\n",
       " u'fully': 1609,\n",
       " u'famous': 1400,\n",
       " u'monday morning': 2895,\n",
       " u'joys': 2357,\n",
       " u'work tonight': 4880,\n",
       " u'sweet': 4192,\n",
       " u'hope well': 2124,\n",
       " u'niece': 3057,\n",
       " u'prince': 3427,\n",
       " u'made day': 2717,\n",
       " u'black': 491,\n",
       " u'airport': 170,\n",
       " u'hates': 1992,\n",
       " u'good morning': 1800,\n",
       " u'flow': 1531,\n",
       " u'sunglasses': 4167,\n",
       " u'agreed': 154,\n",
       " u'boyle': 559,\n",
       " u'picnic': 3306,\n",
       " u'oh good': 3131,\n",
       " u'model': 2886,\n",
       " u'makes sad': 2736,\n",
       " u'fries': 1593,\n",
       " u'fried': 1589,\n",
       " u'grr': 1894,\n",
       " u'gr8': 1854,\n",
       " u'completed': 857,\n",
       " u'incredibly': 2244,\n",
       " u'twilight': 4535,\n",
       " u'ive got': 2297,\n",
       " u'wash': 4714,\n",
       " u'church': 783,\n",
       " u'shaundiviney': 3828,\n",
       " u'like quot': 2563,\n",
       " u'stephenfry': 4078,\n",
       " u'drawing': 1188,\n",
       " u'ghost': 1690,\n",
       " u'highly': 2058,\n",
       " u'total': 4449,\n",
       " u'happy birthday': 1964,\n",
       " u'yuck': 4984,\n",
       " u'brothers': 598,\n",
       " u'certainly': 724,\n",
       " u'excuse': 1357,\n",
       " u'cant wait till': 686,\n",
       " u'way much': 4740,\n",
       " u'love love love': 2674,\n",
       " u'folks': 1540,\n",
       " u'amazing': 200,\n",
       " u'dreams': 1193,\n",
       " u'failure': 1386,\n",
       " u'dollar': 1150,\n",
       " u'difference': 1116,\n",
       " u'texting': 4275,\n",
       " u'182': 30,\n",
       " u'retweet': 3628,\n",
       " u'simple': 3882,\n",
       " u'simply': 3883,\n",
       " u'oh dear': 3129,\n",
       " u'next day': 3040,\n",
       " u'congrats': 870,\n",
       " u'proper': 3453,\n",
       " u'able go': 103,\n",
       " u'amazon': 201,\n",
       " u'gig': 1693,\n",
       " u'knows': 2437,\n",
       " u'known': 2436,\n",
       " u'freak': 1576,\n",
       " u'missin': 2869,\n",
       " u'ground': 1888,\n",
       " u'nice day': 3049,\n",
       " u'thinkin': 4332,\n",
       " u'stairs': 4045,\n",
       " u'pieces': 3312,\n",
       " u'graphics': 1868,\n",
       " u'makeup': 2737,\n",
       " u'control': 883,\n",
       " u'princess': 3428,\n",
       " u'piece': 3311,\n",
       " u'contest': 880,\n",
       " u'lol like': 2620,\n",
       " u'today sad': 4411,\n",
       " u'mon': 2893,\n",
       " u'mom': 2887,\n",
       " u'think im': 4325,\n",
       " u'say quot': 3729,\n",
       " u'shooting': 3846,\n",
       " u'serious': 3802,\n",
       " u'chores': 778,\n",
       " u'art': 277,\n",
       " u'arm': 269,\n",
       " u'called': 655,\n",
       " u'hope everything': 2113,\n",
       " u'productive day': 3441,\n",
       " u'nigga': 3058,\n",
       " u'concerts': 866,\n",
       " u'sick': 3869,\n",
       " u'bringing': 583,\n",
       " u'tech': 4248,\n",
       " u'im work': 2231,\n",
       " u'crowd': 957,\n",
       " u'start day': 4056,\n",
       " u'turned': 4513,\n",
       " u'grounded': 1889,\n",
       " u'trips': 4483,\n",
       " u'today gonna': 4405,\n",
       " u'research': 3613,\n",
       " u'biology': 475,\n",
       " u'stressed': 4123,\n",
       " u'another': 224,\n",
       " u'emo': 1272,\n",
       " u'still': 4082,\n",
       " u'fo': 1538,\n",
       " u'add everyone train': 132,\n",
       " u'address': 136,\n",
       " u'including': 2242,\n",
       " u'special': 4022,\n",
       " u'rain rain': 3502,\n",
       " u'seriously': 3803,\n",
       " u'sorry': 3995,\n",
       " u'got go': 1838,\n",
       " u'asks': 289,\n",
       " u'mariahcarey': 2761,\n",
       " u'boy': 557,\n",
       " u'bow': 553,\n",
       " u'bob': 521,\n",
       " u'ready leave': 3525,\n",
       " u'wake': 4666,\n",
       " u'point': 3362,\n",
       " u'didnt': 1107,\n",
       " u'poor little': 3372,\n",
       " u'proud': 3455,\n",
       " u'manila': 2753,\n",
       " u'finale': 1487,\n",
       " u'finals': 1494,\n",
       " u'disgusting': 1130,\n",
       " u'pleased': 3351,\n",
       " u'coming soon': 844,\n",
       " u'sounds like fun': 4009,\n",
       " u'people': 3265,\n",
       " u'exist': 1360,\n",
       " u'un': 4573,\n",
       " u'afford': 145,\n",
       " u'surgery': 4180,\n",
       " u'twurl': 4551,\n",
       " u'year old': 4952,\n",
       " u'girls': 1699,\n",
       " u'thank goodness': 4282,\n",
       " u'sight': 3872,\n",
       " u'think need': 4329,\n",
       " u'adding': 135,\n",
       " u'two years': 4550,\n",
       " u'december': 1060,\n",
       " u'getting sick': 1685,\n",
       " u'impossible': 2238,\n",
       " u'real': 3528,\n",
       " u'ahhhhhh': 165,\n",
       " u'donnie': 1153,\n",
       " u'products': 3442,\n",
       " u'grow': 1891,\n",
       " u'homework': 2097,\n",
       " u'never': 3013,\n",
       " u'taught': 4233,\n",
       " u'ist': 2287,\n",
       " u'ish': 2282,\n",
       " u'stop': 4105,\n",
       " u'pain': 3213,\n",
       " u'last day school': 2469,\n",
       " u'wimbledon': 4805,\n",
       " u'work tomorrow': 4879,\n",
       " u'moment': 2888,\n",
       " u'minutes': 2858,\n",
       " u'street': 4121,\n",
       " u'mm': 2877,\n",
       " u'mo': 2883,\n",
       " u'mi': 2827,\n",
       " u'ms': 2936,\n",
       " u'mr': 2933,\n",
       " u'blocked': 506,\n",
       " u'late': 2481,\n",
       " u'argentina': 267,\n",
       " u'whale': 4780,\n",
       " u'tommorow': 4425,\n",
       " u'kris': 2442,\n",
       " u'alot': 192,\n",
       " u'thunder': 4355,\n",
       " u'pretty cool': 3418,\n",
       " u'channels': 738,\n",
       " u'constantly': 876,\n",
       " u'sucked': 4148,\n",
       " u'kelly': 2381,\n",
       " u'feel sick': 1442,\n",
       " u'need someone': 2998,\n",
       " u'software': 3955,\n",
       " u'woken': 4843,\n",
       " u'anatomy': 209,\n",
       " u'love lt': 2675,\n",
       " u'happen': 1956,\n",
       " u'morning world': 2914,\n",
       " u'smell': 3926,\n",
       " u'ewww': 1344,\n",
       " u'sadness': 3699,\n",
       " u'strange': 4117,\n",
       " u'tongue': 4432,\n",
       " u'therapy': 4307,\n",
       " u'better get': 452,\n",
       " u'potato': 3391,\n",
       " u'shoot': 3845,\n",
       " u'confused': 868,\n",
       " u'scratch': 3750,\n",
       " u'blessed': 500,\n",
       " u'deep': 1067,\n",
       " u'extremely': 1370,\n",
       " u'aches': 117,\n",
       " u'little girl': 2594,\n",
       " u'9am': 98,\n",
       " u'let go': 2532,\n",
       " u'want get': 4688,\n",
       " u'focus': 1539,\n",
       " u'little brother': 2593,\n",
       " u'plants': 3334,\n",
       " u'really going': 3542,\n",
       " u'weird': 4761,\n",
       " u'hero': 2044,\n",
       " u'bye bye': 644,\n",
       " u'mee': 2801,\n",
       " u'pre': 3403,\n",
       " u'offer': 3121,\n",
       " u'prefer': 3405,\n",
       " u'repair': 3603,\n",
       " u'mtv movie awards': 2942,\n",
       " u'odd': 3120,\n",
       " u'testing': 4269,\n",
       " u'bedroom': 421,\n",
       " u'revise': 3632,\n",
       " u'tummy ache': 4507,\n",
       " u'comin': 840,\n",
       " u'comic': 839,\n",
       " u'two days': 4547,\n",
       " u'trouble': 4484,\n",
       " u'never got': 3015,\n",
       " u'bottle': 546,\n",
       " u'good morning world': 1802,\n",
       " u'hope feel': 2114,\n",
       " u'oven': 3200,\n",
       " u'mypict': 2964,\n",
       " u'ran': 3509,\n",
       " u'raw': 3515,\n",
       " u'ray': 3516,\n",
       " u'check': 748,\n",
       " u'bad times': 364,\n",
       " u'gossip girl': 1833,\n",
       " u'blog': 507,\n",
       " u'though lol': 4341,\n",
       " u'lolz': 2628,\n",
       " u'wish still': 4828,\n",
       " u'18th': 31,\n",
       " u'past': 3246,\n",
       " u'pass': 3240,\n",
       " u'experience': 1365,\n",
       " u'lang': 2462,\n",
       " u'land': 2460,\n",
       " u'guessing': 1904,\n",
       " u'first day': 1511,\n",
       " u'emma': 1271,\n",
       " u'john': 2337,\n",
       " u'shout': 3858,\n",
       " u'adorable': 138,\n",
       " u'soooo': 3987,\n",
       " u'discovered': 1129,\n",
       " u'using': 4613,\n",
       " u'podcast': 3360,\n",
       " u'earn': 1230,\n",
       " u'dealing': 1057,\n",
       " u'140': 22,\n",
       " u'rachel': 3496,\n",
       " u'takin': 4216,\n",
       " u'great weekend': 1880,\n",
       " u'landed': 2461,\n",
       " u'day im': 1032,\n",
       " u'soda': 3951,\n",
       " u'colors': 827,\n",
       " u'despite': 1099,\n",
       " u'three days': 4346,\n",
       " u'clouds': 810,\n",
       " u'cloudy': 811,\n",
       " u'goin bed': 1745,\n",
       " u'oh god': 3130,\n",
       " u'like shit': 2566,\n",
       " u'taste': 4228,\n",
       " u'tasty': 4230,\n",
       " u'weight': 4760,\n",
       " u'taco': 4207,\n",
       " u'mrskutcher': 2935,\n",
       " u'cake': 650,\n",
       " u'relax': 3590,\n",
       " u'listen': 2584,\n",
       " u'tweeterfollow': 4527,\n",
       " u'nooooo': 3086,\n",
       " u'section': 3770,\n",
       " u'grace': 1856,\n",
       " u'session': 3807,\n",
       " u'really need': 3555,\n",
       " u'every1': 1330,\n",
       " u'study': 4136,\n",
       " u'get see': 1665,\n",
       " u'get early': 1653,\n",
       " u'angel': 214,\n",
       " u'bass': 390,\n",
       " u'days work': 1051,\n",
       " u'luckily': 2702,\n",
       " u'getting better': 1679,\n",
       " u'keep': 2378,\n",
       " u'wrote': 4919,\n",
       " u'pure': 3468,\n",
       " u'carry': 696,\n",
       " u'know get': 2422,\n",
       " u'reading': 3520,\n",
       " u'videos': 4636,\n",
       " u'lol well': 2624,\n",
       " u'value': 4624,\n",
       " u'jackalltimelow': 2303,\n",
       " u'hate': 1989,\n",
       " u'kicking': 2389,\n",
       " u'mms': 2882,\n",
       " u'advantage': 142,\n",
       " u'ant': 231,\n",
       " u'events': 1324,\n",
       " u'mission': 2871,\n",
       " u'sad': 3694,\n",
       " u'2morrow': 56,\n",
       " u'cross': 955,\n",
       " u'anyone know': 237,\n",
       " u'losing': 2658,\n",
       " u'tight': 4365,\n",
       " u'sydney': 4203,\n",
       " u'ddlovato': 1053,\n",
       " u'face': 1377,\n",
       " u'fact': 1380,\n",
       " u'bed time': 420,\n",
       " u'good home': 1794,\n",
       " u'officially': 3124,\n",
       " u'band': 377,\n",
       " u'bang': 379,\n",
       " u'hooked': 2107,\n",
       " u'delicious': 1076,\n",
       " u'thurs': 4358,\n",
       " u'dannygokey': 1003,\n",
       " u'3gs': 73,\n",
       " u'bike ride': 468,\n",
       " u'live': 2595,\n",
       " u'jonathan': 2350,\n",
       " u'trying find': 4496,\n",
       " u'hayfever': 2001,\n",
       " u'boston': 543,\n",
       " u'teeth': 4252,\n",
       " u'managed': 2746,\n",
       " u'manager': 2748,\n",
       " u'fish': 1514,\n",
       " u'helps': 2043,\n",
       " u'ohh': 3144,\n",
       " u'dwighthoward': 1222,\n",
       " u'tweet sg': 4520,\n",
       " u'games': 1626,\n",
       " u'anyone else': 236,\n",
       " u'term': 4264,\n",
       " u'hungry': 2168,\n",
       " u'beyonce': 455,\n",
       " u'traveling': 4472,\n",
       " u'baby girl': 344,\n",
       " u'glass': 1711,\n",
       " u'noo': 3081,\n",
       " u'prison': 3430,\n",
       " u'good right': 1808,\n",
       " u'falling': 1394,\n",
       " u'loving': 2692,\n",
       " u'course': 923,\n",
       " u'dunno': 1218,\n",
       " u'spanish': 4018,\n",
       " u'sophie': 3992,\n",
       " u'graduate': 1860,\n",
       " u'really great': 3544,\n",
       " u'major': 2725,\n",
       " u'mummy': 2954,\n",
       " u'texted': 4274,\n",
       " u'freakin': 1577,\n",
       " u'gettin': 1676,\n",
       " u'involved': 2270,\n",
       " u'work till': 4876,\n",
       " u'like said': 2564,\n",
       " u'family guy': 1399,\n",
       " u'personally': 3281,\n",
       " u'ticket': 4361,\n",
       " u'time sleep': 4380,\n",
       " u'butter': 637,\n",
       " u'iron': 2280,\n",
       " u'forced': 1559,\n",
       " u'links': 2580,\n",
       " u'creepy': 949,\n",
       " u'wats': 4730,\n",
       " u'glad hear': 1707,\n",
       " u'michigan': 2831,\n",
       " u'8am': 93,\n",
       " u'pancakes': 3221,\n",
       " u'thankyou': 4297,\n",
       " u'really good': 3543,\n",
       " u'wanted say': 4704,\n",
       " u'laughing': 2490,\n",
       " u'work morning': 4875,\n",
       " u'tomorrow morning': 4429,\n",
       " u'thnx': 4337,\n",
       " u'pregnant': 3406,\n",
       " u'google': 1826,\n",
       " u'iamsoannoyed': 2183,\n",
       " u'fyi': 1620,\n",
       " u'reminds': 3600,\n",
       " u'changed': 734,\n",
       " u'bed early': 417,\n",
       " u'yall': 4940,\n",
       " u'wide': 4798,\n",
       " u'im excited': 2206,\n",
       " u'bowl': 554,\n",
       " u'dope': 1172,\n",
       " u'cold': 822,\n",
       " u'much': 2943,\n",
       " u'stay home': 4070,\n",
       " u'much fun': 2945,\n",
       " u'im really': 2219,\n",
       " u'love new': 2679,\n",
       " u'dont feel': 1158,\n",
       " u'songs': 3976,\n",
       " u'decide': 1062,\n",
       " u'inspired': 2256,\n",
       " u'muscle': 2955,\n",
       " u'feel like': 1438,\n",
       " u'university': 4583,\n",
       " u'bitch': 483,\n",
       " u'jack': 2302,\n",
       " u'begins': 428,\n",
       " u'deal': 1056,\n",
       " u'dead': 1055,\n",
       " u'dear': 1058,\n",
       " u'tennis': 4263,\n",
       " u'needs': 3002,\n",
       " u'reached': 3518,\n",
       " u'chick': 763,\n",
       " u'ttyl': 4501,\n",
       " u'get away': 1648,\n",
       " u'joy': 2356,\n",
       " u'job': 2332,\n",
       " u'joe': 2334,\n",
       " u'jon': 2344,\n",
       " u'better day': 451,\n",
       " u'million': 2848,\n",
       " u'future': 1619,\n",
       " u'hope': 2110,\n",
       " u'official': 3123,\n",
       " u'im going bed': 2212,\n",
       " u'today good day': 4407,\n",
       " u'try get': 4492,\n",
       " u'jamie': 2310,\n",
       " u'wen': 4773,\n",
       " u'laker': 2455,\n",
       " u'school work': 3744,\n",
       " u'limit': 2574,\n",
       " u'starting get': 4060,\n",
       " u'eh': 1257,\n",
       " u'stewart': 4080,\n",
       " u'dies': 1114,\n",
       " u'diet': 1115,\n",
       " u'died': 1112,\n",
       " u'till': 4367,\n",
       " u'gotta': 1848,\n",
       " u'students': 4133,\n",
       " u'ka': 2370,\n",
       " u'kk': 2412,\n",
       " u'ko': 2439,\n",
       " u'blogging': 509,\n",
       " ...}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.vocabulary_\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = (train_fit.toarray().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"top5000.txt\", \"w\") as f:\n",
    "    for key in vocab:\n",
    "        try:\n",
    "            f.write(str(key) + ',' + str(arr[vocab[key]]) + \"\\n\")\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " 'should',\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " 'couldn',\n",
       " 'didn',\n",
       " 'doesn',\n",
       " 'hadn',\n",
       " 'hasn',\n",
       " 'haven',\n",
       " 'isn',\n",
       " 'ma',\n",
       " 'mightn',\n",
       " 'mustn',\n",
       " 'needn',\n",
       " 'shan',\n",
       " 'shouldn',\n",
       " 'wasn',\n",
       " 'weren',\n",
       " 'won',\n",
       " 'wouldn',\n",
       " 'rt',\n",
       " 'com',\n",
       " 'www',\n",
       " 'http',\n",
       " 'https',\n",
       " 'twitter']"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
